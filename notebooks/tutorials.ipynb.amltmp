{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Tracing Context**\n",
        "To demonstrate the core functionality and syntax of nnsight, we’ll define and use a tiny two layer neural network. Our little model here is composed of two submodules – linear layers layer1 and layer2. We specify the sizes of each of these modules and create some complementary example input."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "e6631922-9a91-41e7-be79-a6b6a71e1f02"
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "import torch\n",
        "\n",
        "input_size = 5\n",
        "hidden_dims = 10\n",
        "output_size = 2\n",
        "\n",
        "net = torch.nn.Sequential(\n",
        "    OrderedDict(\n",
        "        [\n",
        "            (\"layer1\", torch.nn.Linear(input_size, hidden_dims)),\n",
        "            (\"layer2\", torch.nn.Linear(hidden_dims, output_size)),\n",
        "        ]\n",
        "    )\n",
        ").requires_grad_(False)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1766114633671
        }
      },
      "id": "73404d6a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The core object of the NNsight package is NNsight. This wraps around a given PyTorch model to enable investigation of its internal parameters."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "a04e326c-f34e-4d61-9fe9-a90c78b1f080"
    },
    {
      "cell_type": "code",
      "source": [
        "from nnsight import NNsight\n",
        "\n",
        "tiny_model = NNsight(net)\n",
        "\n",
        "print(tiny_model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sequential(\n  (layer1): Linear(in_features=5, out_features=10, bias=True)\n  (layer2): Linear(in_features=10, out_features=2, bias=True)\n)\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1766114641357
        }
      },
      "id": "14082d19-8740-442a-855c-a2b3fd865120"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing a PyTorch model shows a named hierarchy of modules which is very useful when accessing sub-components directly. NNsight reflect the same hierarchy and can be similarly printed."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "2bd2f613-edbe-4f3e-98dd-6472815ee4db"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main tool with nnsight is a context for tracing. We enter the tracing context by calling model.trace(<input>) on an NNsight model, which defines how we want to run the model. Inside the context, we will be able to customize how the neural network runs. The model is actually run upon exiting the tracing context."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "0eda7e3f-5309-4f9e-94b8-135cb5ec1df0"
    },
    {
      "cell_type": "code",
      "source": [
        "# random input\n",
        "input = torch.rand((1, input_size))\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1766114648773
        }
      },
      "id": "c86bae18-ed8e-4670-ae84-53fdcdb23a16"
    },
    {
      "cell_type": "code",
      "source": [
        "with tiny_model.trace(input) as tracer:\n",
        "\n",
        "    output = tiny_model.output.save()\n",
        "    # output = tiny_model.output.save()\n",
        "\n",
        "print('output:', output)\n",
        "print('input:', input)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "output: tensor([[0.2346, 0.3191]])\ninput: tensor([[0.5555, 0.5540, 0.5529, 0.1200, 0.9673]])\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1766113684836
        }
      },
      "id": "9fcde80c-ee81-4e6f-8137-601fbf339a87"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Success! We now have the model output. We just completed out first intervention using nnsight. Each time we access a module’s input or output, we create an intervention in the neural network’s forward pass. Collectively these requests form the intervention graph. We call the process of executing it alongside the model’s normal computation graph, interleaving."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "f23b4905-0901-4e1d-b246-a6b28a145db0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we don’t need to access anything other than the model’s final output (i.e., the model’s predicted next token), we can call the tracing context with trace=False and not use it as a context. This could be useful for simple inference using NNsight.\n",
        "\n",
        "```\n",
        "output = model.trace(<inputs>, trace=False)\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "fee8713e-0b85-400e-8f50-91105b06c640"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s access the output of the first layer (which we’ve named layer1):\n",
        "with tiny_model.trace(input) as tracer:\n",
        "\n",
        "    l1_output = tiny_model.layer1.output.save()\n",
        "\n",
        "print(f'Layer 1 output:', l1_output)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Layer 1 output: tensor([[ 0.1353,  0.8325,  0.1603, -0.3851, -0.0496,  0.1205,  0.2969, -0.2429,\n          0.0556, -0.3322]])\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1766022421901
        }
      },
      "id": "09854b09-04e9-4edb-a1e6-3f931664bbb5"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}